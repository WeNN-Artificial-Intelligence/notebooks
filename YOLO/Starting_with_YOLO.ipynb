{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e37a29f",
   "metadata": {},
   "source": [
    "### Add libraries & read the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aec61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 962\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"bioimage.png\")\n",
    "img_height = img.shape[0]\n",
    "img_width = img.shape[1]\n",
    "print(img_width, img_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b4d10",
   "metadata": {},
   "source": [
    "### Show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53136484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652b12e",
   "metadata": {},
   "source": [
    "### Converting image to blob\n",
    "##### What is blob? Images converted to tensors with 4 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c073378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 416, 416)\n"
     ]
    }
   ],
   "source": [
    "img_blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), swapRB=True,crop=False) #params: img resource, scale factorm, blob dimensions(2),BGR to RGB,to crop?\n",
    "print(img_blob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d49b03",
   "metadata": {},
   "source": [
    "### Read and split labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "107481eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 [\"['person\", 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'trafficlight', 'firehydrant', 'stopsign', 'parkingmeter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sportsball', 'kite', 'baseballbat', 'baseballglove', 'skateboard', 'surfboard', 'tennisracket', 'bottle', 'wineglass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hotdog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cellphone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddybear', 'hairdrier', \"toothbrush']\"]\n"
     ]
    }
   ],
   "source": [
    "label_file = open(\"labels.txt\", 'r')\n",
    "labels = [word.replace('\"','') for word in str(label_file.readlines()).split(',')]\n",
    "print(len(labels),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e470c4",
   "metadata": {},
   "source": [
    "### Create color list for bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1441269a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = [\"0,255,0\",\"0,0,255\",\"255,0,0\",\"0,120,30\",\"0,30,120\",\"50,50,50\",\"50,0,50\",\"50,50,100\"]\n",
    "colors = [np.array(color.split(\",\")).astype(\"int\") for color in colors]\n",
    "colors = np.array(colors)\n",
    "colors = np.tile(colors,(10,1)) #copying color list 10 times to fill the array with same numbers vertically\n",
    "len(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9541fe6e",
   "metadata": {},
   "source": [
    "### Read the model and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05588629",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn.readNetFromDarknet(\"model/yolov3.cfg\",\"model/yolov3.weights\")\n",
    "layers = model.getLayerNames()\n",
    "output_layers = [layers[int(layer)-1] for layer in model.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b6a3bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.04120015, 0.04584586, 0.37053925, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.04649337, 0.03197153, 0.27123636, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.04628211, 0.03658194, 0.8056842 , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.9572996 , 0.9502675 , 0.4856819 , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9624371 , 0.96359324, 0.3226212 , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9719613 , 0.96827793, 0.8332815 , ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32),\n",
       " array([[0.01874625, 0.02464668, 0.05372084, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.01951553, 0.01811345, 0.39146778, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.02242082, 0.01782617, 0.07499409, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.977514  , 0.97652143, 0.03970766, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9817187 , 0.9790996 , 0.39284307, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9789926 , 0.98303056, 0.07213028, ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32),\n",
       " array([[0.00860759, 0.00651248, 0.01481533, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.00923317, 0.01115428, 0.01695344, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.00939493, 0.008302  , 0.20146197, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.991072  , 0.9920345 , 0.01440599, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.99183494, 0.98799735, 0.01589114, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9881985 , 0.9910502 , 0.17958714, ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setInput(img_blob)\n",
    "detection_layers = model.forward(output_layers) # reaching out to the values in output layers\n",
    "detection_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a336a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
