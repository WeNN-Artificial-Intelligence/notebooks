{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade96d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc00ac0",
   "metadata": {},
   "source": [
    "### Read and the split labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bee3f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'trafficlight', 'firehydrant', 'stopsign', 'parkingmeter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sportsball', 'kite', 'baseballbat', 'baseballglove', 'skateboard', 'surfboard', 'tennisracket', 'bottle', 'wineglass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hotdog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cellphone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddybear', 'hairdrier', 'toothbrush']\n",
      "person\n"
     ]
    }
   ],
   "source": [
    "label_file = open(\"model/labels.txt\", 'r')\n",
    "labels = [word.replace('\"','').replace(\"'\",'') for word in label_file.read().split(',')]\n",
    "label_file.close()\n",
    "print(len(labels),labels)\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a422a3",
   "metadata": {},
   "source": [
    "### Create color list for bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde6b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = [\"0,255,0\",\"0,0,255\",\"255,0,0\",\"0,120,30\",\"0,30,120\",\"50,50,50\",\"50,0,50\",\"50,50,100\"]\n",
    "colors = [np.array(color.split(\",\")).astype(\"int\") for color in colors]\n",
    "colors = np.array(colors)\n",
    "colors = np.tile(colors,(10,1)) #copying color list 10 times to fill the array with same numbers vertically\n",
    "len(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c8dec",
   "metadata": {},
   "source": [
    "### Create color list for bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1447fba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = [\"0,255,0\",\"0,0,255\",\"255,0,0\",\"0,120,30\",\"0,30,120\",\"50,50,50\",\"50,0,50\",\"50,50,100\"]\n",
    "colors = [np.array(color.split(\",\")).astype(\"int\") for color in colors]\n",
    "colors = np.array(colors)\n",
    "colors = np.tile(colors,(10,1)) #copying color list 10 times to fill the array with same numbers vertically\n",
    "len(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825504d6",
   "metadata": {},
   "source": [
    "### Read the model and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d32059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn.readNetFromDarknet(\"model/yolov3.cfg\",\"model/yolov3.weights\")\n",
    "layers = model.getLayerNames()\n",
    "output_layers = [layers[int(layer)-1] for layer in model.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01739fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted object: person: 99.63%\n",
      "predicted object: remote: 50.21%\n",
      "predicted object: person: 99.99%\n",
      "predicted object: person: 99.99%\n",
      "predicted object: person: 99.99%\n",
      "predicted object: person: 99.86%\n",
      "predicted object: person: 99.94%\n",
      "predicted object: person: 99.98%\n",
      "predicted object: person: 99.99%\n",
      "predicted object: person: 99.96%\n",
      "predicted object: person: 99.99%\n",
      "predicted object: person: 99.79%\n",
      "predicted object: person: 96.97%\n",
      "predicted object: cellphone: 92.13%\n",
      "predicted object: cellphone: 99.64%\n",
      "predicted object: person: 99.53%\n",
      "predicted object: person: 99.49%\n",
      "predicted object: cellphone: 97.94%\n",
      "predicted object: cellphone: 99.33%\n",
      "predicted object: person: 99.26%\n",
      "predicted object: cellphone: 99.36%\n",
      "predicted object: person: 99.35%\n",
      "predicted object: person: 99.66%\n",
      "predicted object: cellphone: 99.40%\n",
      "predicted object: person: 99.82%\n",
      "predicted object: cellphone: 99.07%\n",
      "predicted object: person: 99.98%\n",
      "predicted object: person: 99.94%\n",
      "predicted object: person: 99.98%\n",
      "predicted object: cup: 78.71%\n",
      "predicted object: person: 99.94%\n",
      "predicted object: cup: 97.61%\n",
      "predicted object: person: 99.96%\n",
      "predicted object: banana: 89.72%\n",
      "predicted object: person: 99.97%\n",
      "predicted object: cup: 73.85%\n",
      "predicted object: person: 99.94%\n",
      "predicted object: cup: 80.56%\n",
      "predicted object: person: 99.94%\n",
      "predicted object: cup: 79.30%\n",
      "predicted object: person: 99.94%\n",
      "predicted object: banana: 84.45%\n",
      "predicted object: person: 99.99%\n",
      "predicted object: person: 99.96%\n",
      "predicted object: person: 99.98%\n",
      "predicted object: person: 99.96%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_width = frame.shape[1]\n",
    "    frame_height = frame.shape[0]\n",
    "\n",
    "    frame_blob = cv2.dnn.blobFromImage(frame, 1/255, (416,416), swapRB=True,crop=False)\n",
    "    model.setInput(frame_blob)\n",
    "    detection_layers = model.forward(output_layers)\n",
    "\n",
    "    ids_list = []\n",
    "    boxes_list = []\n",
    "    confidences_list = []\n",
    "    for detection_layer in detection_layers:\n",
    "        for object_detection in detection_layer:\n",
    "            scores = object_detection[5:]\n",
    "            predicted_id = np.argmax(scores)\n",
    "            confidence = scores[predicted_id]\n",
    "            if confidence > 0.20: #draw bounding box if confidence is higher than ..\n",
    "                label = labels[predicted_id]\n",
    "                bounding_box = object_detection[0:4] * np.array([frame_width,frame_height,frame_width,frame_height])\n",
    "                (box_center_x, box_center_y,box_width, box_height) = bounding_box.astype(\"int\")\n",
    "\n",
    "                start_x = int(box_center_x - (box_width/2))\n",
    "                start_y = int(box_center_y - (box_height/2))\n",
    "\n",
    "                ## non-maximum surpression step 2 ##\n",
    "                ids_list.append(predicted_id)\n",
    "                confidences_list.append(float(confidence))\n",
    "                boxes_list.append([start_x,start_y,int(box_width),int(box_height)])\n",
    "                ## non-maximum surpression step 2 ##\n",
    "\n",
    "    ## non-maximum surpression step 3 ##\n",
    "    max_ids = cv2.dnn.NMSBoxes(boxes_list, confidences_list, 0.5, 0.4)\n",
    "    for max_id in max_ids:\n",
    "        max_class_id = max_id[0]\n",
    "        box = boxes_list[max_class_id]\n",
    "        start_x = box[0]\n",
    "        start_y = box[1]\n",
    "        box_width = box[2]\n",
    "        box_height = box[3]\n",
    "\n",
    "        predicted_id = ids_list[max_class_id]\n",
    "        label = labels[predicted_id]\n",
    "        confidence = confidences_list[max_class_id]\n",
    "    ## non-maximum surpression step 3 ##\n",
    "\n",
    "        end_x = start_x + box_width\n",
    "        end_y = start_y + box_height\n",
    "\n",
    "        box_color = colors[predicted_id]\n",
    "        box_color = [int(each) for each in box_color]\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label,confidence*100)\n",
    "        print(\"predicted object: {}\".format(label))\n",
    "\n",
    "        cv2.rectangle(frame, (start_x, start_y),(end_x, end_y),box_color,2)\n",
    "        cv2.putText(frame, label, (start_x, start_y-10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color,1)\n",
    "    cv2.imshow(\"Detection window\", frame)\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    #display(Image.fromarray(frame))\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f4790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4deee30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
