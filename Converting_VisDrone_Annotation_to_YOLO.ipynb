{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Converting_VisDrone_Annotation_to_YOLO.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRkDBf3BkhTepEM47/yOfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WeNN-Artificial-Intelligence/notebooks/blob/ilker_study/Converting_VisDrone_Annotation_to_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gdown\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "q5oWmHi5-6vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "grbtPsTIIm4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path binding-shortcut\n",
        "!ln -s /content/drive/My Drive /content/example"
      ],
      "metadata": {
        "id": "OVG2fDmWgxTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1a2oHjcEcwXP8oUF95qiwrqzACb2YlUhn\n",
        "!unzip VisDrone2019-DET-train.zip"
      ],
      "metadata": {
        "id": "-oypfOiAc2jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "input_img_folder = 'VisDrone2019-DET-train/images'\n",
        "input_ann_folder = 'VisDrone2019-DET-train/annotations'\n",
        "output_ann_folder = 'VisDrone2019-DET-train/annotations_new'\n",
        "output_img_folder = 'VisDrone2019-DET-train/images_new'\n",
        "\n",
        "os.makedirs(output_img_folder, exist_ok=True)\n",
        "os.makedirs(output_ann_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "image_list = os.listdir(input_img_folder)\n",
        "annotation_list = os.listdir(input_ann_folder)\n",
        "\n",
        "label_dict = {\n",
        "\t\"0\" : \"Ignore\",\n",
        "\t\"1\" : \"Pedestrian\",\n",
        "\t\"2\" : \"People\",\n",
        "\t\"3\" : \"Bicycle\",\n",
        "\t\"4\" : \"Car\",\n",
        "\t\"5\" : \"Van\",\n",
        "\t\"6\" : \"Truck\",\n",
        "\t\"7\" : \"Tricycle\",\n",
        "\t\"8\" : \"Awning-tricycle\",\n",
        "\t\"9\" : \"Bus\",\n",
        "\t\"10\" : \"Motor\",\n",
        "\t\"11\" : \"Others\"\n",
        "}\n",
        "\n",
        "thickness = 2\n",
        "color = (255,0,0)\n",
        "count = 0\n",
        "\n",
        "def object_string(label, bbox):\n",
        "\treq_str = '''\n",
        "\t<object>\n",
        "\t\t<name>{}</name>\n",
        "\t\t<pose>Unspecified</pose>\n",
        "\t\t<truncated>0</truncated>\n",
        "\t\t<difficult>0</difficult>\n",
        "\t\t<bndbox>\n",
        "\t\t\t<xmin>{}</xmin>\n",
        "\t\t\t<ymin>{}</ymin>\n",
        "\t\t\t<xmax>{}</xmax>\n",
        "\t\t\t<ymax>{}</ymax>\n",
        "\t\t</bndbox>\n",
        "\t</object>\n",
        "\t'''.format(label, bbox[0], bbox[1], bbox[2], bbox[3])\n",
        "\treturn req_str\n",
        "\n",
        "for annotation in annotation_list:\n",
        "\tannotation_path = os.path.join(os.getcwd(), input_ann_folder, annotation)\n",
        "\txml_annotation = annotation.split('.txt')[0] + '.xml'\n",
        "\txml_path = os.path.join(os.getcwd(), output_ann_folder, xml_annotation)\n",
        "\timg_file = annotation.split('.txt')[0] + '.jpg'\n",
        "\timg_path = os.path.join(os.getcwd(), input_img_folder, img_file)\n",
        "\toutput_img_path = os.path.join(os.getcwd(), output_img_folder, img_file)\n",
        "\timg = cv2.imread(img_path)\n",
        "\tannotation_string_init = '''\n",
        "<annotation>\n",
        "\t<folder>annotations</folder>\n",
        "\t<filename>{}</filename>\n",
        "\t<path>{}</path>\n",
        "\t<source>\n",
        "\t\t<database>Unknown</database>\n",
        "\t</source>\n",
        "\t<size>\n",
        "\t\t<width>{}</width>\n",
        "\t\t<height>{}</height>\n",
        "\t\t<depth>{}</depth>\n",
        "\t</size>\n",
        "\t<segmented>0</segmented>'''.format(img_file, img_path, img.shape[0], img.shape[1], img.shape[2])\n",
        "\n",
        "\tfile = open(annotation_path, 'r')\n",
        "\tlines = file.readlines()\n",
        "\tfor line in lines:\n",
        "\t\tnew_line = line.strip('\\n').split(',')\n",
        "\t\tnew_coords_min = (int(new_line[0]), int(new_line[1]))\n",
        "\t\tnew_coords_max = (int(new_line[0])+int(new_line[2]), int(new_line[1])+int(new_line[3]))\n",
        "\t\tbbox = (int(new_line[0]), int(new_line[1]), int(new_line[0])+int(new_line[2]), int(new_line[1])+int(new_line[3]))\n",
        "\t\tlabel = label_dict.get(new_line[5])\n",
        "\t\treq_str = object_string(label, bbox)\n",
        "\t\tannotation_string_init = annotation_string_init + req_str\n",
        "\t\t#cv2.rectangle(img, new_coords_min, new_coords_max, color, thickness)\n",
        "\tcv2.imwrite(output_img_path, img)\n",
        "\tannotation_string_final = annotation_string_init + '</annotation>'\n",
        "\tf = open(xml_path, 'w')\n",
        "\tf.write(annotation_string_final)\n",
        "\tf.close()\n",
        "\tcount += 1\n",
        "\tprint('[INFO] Completed {} image(s) and annotation(s) pair'.format(count))"
      ],
      "metadata": {
        "id": "AprVJ8GStooo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hai-h-nguyen/Yolo2Pascal-annotation-conversion.git"
      ],
      "metadata": {
        "id": "FL2AWLzFD2vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!cp -R /content/VisDrone2019-DET-train/annotations_new/. /content/VisDrone2019-DET-train/images/\n",
        "#!rm /content/VisDrone2019-DET-train/images/*.xml \n",
        "!ls /content/VisDrone2019-DET-train/images/"
      ],
      "metadata": {
        "id": "PTTZfPrMFXWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyQt5\n",
        "%cd Yolo2Pascal-annotation-conversion/pascal2yolo/\n",
        "!python voc2yolo.py /content/VisDrone2019-DET-train/images/\n"
      ],
      "metadata": {
        "id": "RK2-UHqyGWm_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}